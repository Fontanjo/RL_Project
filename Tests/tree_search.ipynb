{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2c61b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_Snake\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfa8642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Snake-v0', player='computer', width=10, height=10, solid_border=False, reward_mode='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1acfccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_search_best_action(env, dept, target_reward):\n",
    "    global stop\n",
    "    stop = False\n",
    "    results, act = tree_search_best_action_rec(env, dept, acts=[], target_reward=target_reward)\n",
    "#     print(results)\n",
    "    return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e76db44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop as soon as a path can reach the end without dying\n",
    "def check_trap(env, dept):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61e13b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = False\n",
    "def tree_search_best_action_rec(env, dept, acts, target_reward, dept_after_reward=4):\n",
    "    global stop\n",
    "    actions = [0, 1, 2]\n",
    "    \n",
    "    # Clone envs\n",
    "    envs = [env.clone() for _ in actions]\n",
    "    \n",
    "    # Play each action\n",
    "    obss, rewards, dones, _ = np.array([e.step(a) for e,a in zip(envs, actions)]).T\n",
    "\n",
    "    # Termination case\n",
    "    if dept == 0:\n",
    "        valids = [i for i, x in enumerate(rewards) if x == max(rewards)]\n",
    "        i = np.random.choice(valids)\n",
    "        return rewards[i], i\n",
    "    \n",
    "    remaining_dept = [dept - 1 for _ in actions]\n",
    "    \n",
    "    # Mark as done loops that have already reached the target\n",
    "    # Allows to slightly accellerate the algorithm, but suffers from the same\n",
    "    # problems of Q-learning and SARSA (snake traps itself)\n",
    "    for i, r in enumerate(rewards):\n",
    "        if r >= target_reward:\n",
    "            dones = [True for _ in range(len(dones))] # Stop search for this branch\n",
    "#             stop = True # Send the stop signal to all branches\n",
    "#             dones[i] = True # Stop search for given path\n",
    "#             remaining_dept = [0 for _ in actions] # Stop search for other paths, limit for given one\n",
    "#             remaining_dept[i] = min(dept_after_reward, remaining_dept[i]) # Limit the search for the given path\n",
    "         \n",
    "    # Check if external stop - makes it very fast limiting dept in most cases\n",
    "    if stop:\n",
    "        dones = [True for _ in range(len(dones))]\n",
    "            \n",
    "    \n",
    "    results, _ = np.array([tree_search_best_action_rec(e, dept-1, acts + [i], target_reward=target_reward) if not dones[i] else (0, -1) for i, e, d in zip(range(len(actions)), envs, remaining_dept)]).T\n",
    "#     results, _ = np.array([tree_search_best_action_rec(e, dept-1, acts + [i], target_reward=target_reward) if not dones[i] else (0, -1) for i, e in enumerate(envs)]).T\n",
    "#     results = [tree_search_best_action_rec(e, dept-1, acts + [i]) for i, e in enumerate(envs)]\n",
    "\n",
    "\n",
    "    # Add reward MULTIPLIED by dept. In this way, sort of discount rewards more far away\n",
    "    # Without this trick, it is possible that the snake turn around the target without ever eating it, since a \n",
    "    # position in which we can eat the target in N steps has the same value as the one in which we eat it\n",
    "    results = [results[i] + rewards[i] * (1 + dept/1000) for i in range(len(results))]\n",
    "#     results = [results[i] + rewards[i] for i in range(len(results))]\n",
    "\n",
    "    \n",
    "    # If multiple results with same (max) value, choose random among them \n",
    "    valids = [i for i, x in enumerate(results) if x == max(results)]\n",
    "    \n",
    "    # Randomly choose one of the best actions\n",
    "    i = np.random.choice(valids)\n",
    "    \n",
    "#     if dept == 5: print(results)\n",
    "    return results[i], i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4489185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_epoch(env, render = False, dept=5, target_reward = 10, sleep_time = 0.5):\n",
    "    \n",
    "    # Reset env\n",
    "    obs = env.reset()\n",
    "\n",
    "    done = False\n",
    "    \n",
    "    # Sum the rewards\n",
    "    total_rew = 0\n",
    "    \n",
    "    i = 0\n",
    "    while not done:\n",
    "        # Show\n",
    "        if render: env.render()\n",
    "        # Choose next action\n",
    "        new_act = tree_search_best_action(env, dept=dept, target_reward=target_reward)\n",
    "#         print(new_act)\n",
    "        # Act in the env\n",
    "        obs, reward, done, info = env.step(new_act)\n",
    "        # Store reward\n",
    "        total_rew += reward\n",
    "        # Slow render\n",
    "        if render: time.sleep(sleep_time)\n",
    "        i += 1\n",
    "        if i == 100: break\n",
    "            \n",
    "    # Return total reward\n",
    "    return total_rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb51c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 7\n",
    "start = time.time()\n",
    "r = play_epoch(env = env, render = True, dept=i, target_reward=10)\n",
    "stop = time.time()\n",
    "print(f'i = {i}, total reward = {r}, time = {round(stop-start, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(4,5):\n",
    "#     start = time.time()\n",
    "#     r = play_epoch(env = env, render = True, dept=i)\n",
    "#     stop = time.time()\n",
    "#     print(f'i = {i}, total reward = {r}, time = {round(stop-start, 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54154ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_iterations = 1\n",
    "\n",
    "# rewards = []\n",
    "# eps = []\n",
    "\n",
    "# # Train\n",
    "# for i in tqdm(range(nb_iterations)):\n",
    "#     # Play a game\n",
    "#     r = play_epoch(env = env, render = False)\n",
    "    \n",
    "#     # Keep track of reward\n",
    "#     rewards.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873b8621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot rewards\n",
    "# plt.plot(range(len(rewards)), rewards)\n",
    "# # Plot moving average\n",
    "# plt.plot(range(len(rewards)), pd.Series(rewards).rolling(1000).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6426c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
